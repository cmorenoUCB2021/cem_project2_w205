{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f281429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ade54e",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. How many assesstments are in the dataset?\n",
    "2. What's the name of your Kafka topic? How did you come up with that name?\n",
    "3. How many people took *Learning Git*?\n",
    "4. What is the least common course taken? And the most common?\n",
    "5. Add any query(ies) you think will help the data science team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aef990",
   "metadata": {},
   "source": [
    "### Steps for Running the Project\n",
    "\n",
    "#### 1. Setup Docker Compose, Get Data and Explore Data Structure:\n",
    "\n",
    "- **Create a 'docker-compose.yml' file** including the following services: zookeeper, kafka, cloudera, spark, mids.  Please see details for yml file in **\"Structure for docker-compose.yml file\"** below.\n",
    "  \n",
    "- **Get JSON file with information**.  The name of the file is \"assessment-attempts-20180128-121051-nested.json\" - using the following command:\n",
    "\n",
    "```\n",
    "curl -L -o assessment-attempts-20180128-121051-nested.json https://goo.gl/ME6hjp`\n",
    "```\n",
    "\n",
    "- **Explore the JSON file with JQ** to get an idea of the structure - the following command was used to understand the fields included in the JSON file:\n",
    "\n",
    "```\n",
    "cat assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | head -1 | jq .\n",
    "```\n",
    "\n",
    "This indicates that there are 10 fields in the main level of the JSON file: (1) 'keen_timestamp', (2) 'max_attempts', (3) 'started_at', (4) 'base_exam_id', (5) 'user_exam_id', (6) 'sequences', (7) 'keen_created_at', (8) 'certification', (9) 'keen_id', (10) 'exam_name'.  \n",
    "In addition, the field \"sequences\" include several nested levels.  Details are presented in section **\"Top Line Structure of JSON File\"** included later in this report.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195103e",
   "metadata": {},
   "source": [
    "#### 2. Run Docker Compose, Define Kafka Topic and Produce Data to Kafka Topic\n",
    "- **Once the docker-compose.yml file has been created, perform a pull to update the services and images:**\n",
    "\n",
    "```\n",
    "docker-compose pull\n",
    "```\n",
    "\n",
    "- **Run docker compose:**\n",
    "\n",
    "```\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "- **Check logs for kafka (use CTRL-C to stop):**\n",
    "\n",
    "```\n",
    "docker-compose logs -f kafka\n",
    "```\n",
    "\n",
    "- **Create a topic for Kafka.** The name of the topic is \"examtaken\" as the dataset relates to exams taken for courses from November 2017 to January 2018.  The topic was created with the following command:  \n",
    "\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --create --topic examtaken --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "```\n",
    "  \n",
    "- **Check for kafka topic:**\n",
    "\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --describe --topic examtaken --zookeeper zookeeper:32181\n",
    "```\n",
    "\n",
    "- **Use kafkacat to produce test messages to the `examtaken` topic:**   \n",
    "\n",
    "```\n",
    "docker-compose exec mids bash -c \"cat /w205/project-2-cmorenoUCB2021/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t examtaken\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701ad85",
   "metadata": {},
   "source": [
    "#### 3. Use \"pyspark\" to read raw data from kafka topic:\n",
    "\n",
    "- **Run pyspark process using the `spark` container:**\n",
    "\n",
    "```\n",
    "docker-compose exec spark pyspark\n",
    "```\n",
    "\n",
    "- **Import libraries to work with file:**  \n",
    "```\n",
    "import sys\n",
    "import json\n",
    "from pyspark.sql import Row\n",
    "```  \n",
    "  \n",
    "  \n",
    "- **Read from kafka (using the topic 'examtaken':**\n",
    "\n",
    "```\n",
    "exams = park.read.format(\"kafka\").option(\"kafka.bootstrap.servers\",\"kafka:29092\").option(\"subscribe\",“examtaken\").option(\"startingOffsets\",\"earliest\").option(\"endingOffsets\", \"latest\").load()\n",
    "```\n",
    "\n",
    "- **Cache this to cut back on warnings:**\n",
    "\n",
    "```\n",
    "exams.cache()\n",
    "```\n",
    "\n",
    "- **printSchema of what was read:** \n",
    "\n",
    "```\n",
    "exams.printSchema()\n",
    "```\n",
    "\n",
    "- **Ensure UTF8 decoder is used:**\n",
    "\n",
    "```\n",
    "sys.stdout = open(sys.stdout.fileno(), mode='w', encoding='utf8', buffering=1)\n",
    "```\n",
    "\n",
    "- **Read the `value`s as strings, and show them:**\n",
    "```\n",
    "examsall = exams.rdd.map(lambda x: json.loads(x.value)).toDF()\n",
    "examsall.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01190b30",
   "metadata": {},
   "source": [
    "#### 4. Use SparkSQL to explore data and answer business questions:\n",
    "\n",
    "- **Create a Spark \"TempTable\" (or \"View\")**\n",
    "\n",
    "```\n",
    "examsall.registerTempTable('examview')\n",
    "```\n",
    "\n",
    "- **Use SparkSQL to answer business questions:**\n",
    "  \n",
    "  \n",
    "*1. How many assesstments are in the dataset?:*\n",
    "\n",
    "```\n",
    "spark.sql(\"select count(exam_name) from examview\").show()\n",
    "```\n",
    "```\n",
    "+----------------+\n",
    "|count(exam_name)|\n",
    "+----------------+\n",
    "|            3280|\n",
    "+----------------+\n",
    "```\n",
    "\n",
    "*3. How many people took *Learning Git*?*  \n",
    "\n",
    "```\n",
    "spark.sql(\"select count(exam_name) from examview WHERE  exam_name = 'Learning Git' \").show()\n",
    "```\n",
    "```\n",
    "+----------------+\n",
    "|count(exam_name)|\n",
    "+----------------+\n",
    "|             394|\n",
    "+----------------+\n",
    "```\n",
    "\n",
    "*4. What is the least common course taken?*\n",
    "```\n",
    "spark.sql(\"select exam_name, count(keen_id) as num_exam FROM examview GROUP BY exam_name ORDER BY num_exam limit 5\").show()\n",
    "```\n",
    "- The 10 least common courses are shown in the table below:\n",
    "\n",
    "```\n",
    "+--------------------+--------+                                                 \n",
    "|           exam_name|num_exam|\n",
    "+--------------------+--------+\n",
    "|Nulls, Three-valu...|       1|\n",
    "|Native Web Apps f...|       1|\n",
    "|Learning to Visua...|       1|\n",
    "|Operating Red Hat...|       1|\n",
    "|Understanding the...|       2|\n",
    "+--------------------+--------+\n",
    "```\n",
    "\n",
    "\n",
    "*5. What is the most common course taken?*\n",
    "```\n",
    "spark.sql(\"select exam_name, count(keen_id) as num_exam FROM examview GROUP BY exam_name ORDER BY num_exam DESC limit 5\").show()\n",
    "```\n",
    "- The top ten couses taken are presented in the following table:\n",
    "\n",
    "```\n",
    "+--------------------+--------+                                                 \n",
    "|           exam_name|num_exam|\n",
    "+--------------------+--------+\n",
    "|        Learning Git|     394|\n",
    "|Introduction to P...|     162|\n",
    "|Intermediate Pyth...|     158|\n",
    "|Introduction to J...|     158|\n",
    "|Learning to Progr...|     128|\n",
    "+--------------------+--------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699fdc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebb95fa6",
   "metadata": {},
   "source": [
    "### Structure for 'docker-compose.yml' file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bb65a",
   "metadata": {},
   "source": [
    "```\n",
    "version: '2'\n",
    "services:\n",
    "  zookeeper:\n",
    "    image: confluentinc/cp-zookeeper:latest\n",
    "    environment:\n",
    "      ZOOKEEPER_CLIENT_PORT: 32181\n",
    "      ZOOKEEPER_TICK_TIME: 2000\n",
    "    expose:\n",
    "      - \"2181\"\n",
    "      - \"2888\"\n",
    "      - \"32181\"\n",
    "      - \"3888\"\n",
    "\n",
    "  kafka:\n",
    "    image: confluentinc/cp-kafka:latest\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "    environment:\n",
    "      KAFKA_BROKER_ID: 1\n",
    "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181\n",
    "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092\n",
    "      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n",
    "    expose:\n",
    "      - \"9092\"\n",
    "      - \"29092\"\n",
    "\n",
    "  cloudera:\n",
    "    image: midsw205/cdh-minimal:latest\n",
    "    expose:\n",
    "      - \"8020\" # nn\n",
    "      - \"50070\" # nn http\n",
    "      - \"8888\" # hue\n",
    "    #ports:\n",
    "    #- \"8888:8888\"\n",
    "\n",
    "  spark:\n",
    "    image: midsw205/spark-python:0.0.5\n",
    "    stdin_open: true\n",
    "    tty: true\n",
    "    volumes:\n",
    "      - ~/w205:/w205\n",
    "    command: bash\n",
    "    depends_on:\n",
    "      - cloudera\n",
    "    environment:\n",
    "      HADOOP_NAMENODE: cloudera\n",
    "\n",
    "  mids:\n",
    "    image: midsw205/base:latest\n",
    "    stdin_open: true\n",
    "    tty: true\n",
    "    volumes:\n",
    "      - ~/w205:/w205\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd0f3a",
   "metadata": {},
   "source": [
    "### Top Line Structure of JSON File:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4f847",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "  \"keen_timestamp\": \"1516717442.735266\",\n",
    "  \"max_attempts\": \"1.0\",\n",
    "  \"started_at\": \"2018-01-23T14:23:19.082Z\",\n",
    "  \"base_exam_id\": \"37f0a30a-7464-11e6-aa92-a8667f27e5dc\",\n",
    "  \"user_exam_id\": \"6d4089e4-bde5-4a22-b65f-18bce9ab79c8\",\n",
    "  \"sequences\": {\n",
    "    \"questions\": [\n",
    "      {\n",
    "        \"user_incomplete\": true,\n",
    "        \"user_correct\": false,\n",
    "        \"options\": [\n",
    "          {\n",
    "            \"checked\": true,\n",
    "            \"at\": \"2018-01-23T14:23:24.670Z\",\n",
    "            \"id\": \"49c574b4-5c82-4ffd-9bd1-c3358faf850d\",\n",
    "            \"submitted\": 1,\n",
    "            \"correct\": true\n",
    "          },\n",
    "          {\n",
    "            \"checked\": true,\n",
    "            \"at\": \"2018-01-23T14:23:25.914Z\",\n",
    "            \"id\": \"f2528210-35c3-4320-acf3-9056567ea19f\",\n",
    "            \"submitted\": 1,\n",
    "            \"correct\": true\n",
    "          },\n",
    "          {\n",
    "            \"checked\": false,\n",
    "            \"correct\": true,\n",
    "            \"id\": \"d1bf026f-554f-4543-bdd2-54dcf105b826\"\n",
    "          }\n",
    "        ],\n",
    "        \"user_submitted\": true,\n",
    "        \"id\": \"7a2ed6d3-f492-49b3-b8aa-d080a8aad986\",\n",
    "        \"user_result\": \"missed_some\"\n",
    "      },\n",
    "      {\n",
    "        \"user_incomplete\": false,\n",
    "        \"user_correct\": false,\n",
    "        \"options\": [\n",
    "          {\n",
    "            \"checked\": true,\n",
    "            \"at\": \"2018-01-23T14:23:30.116Z\",\n",
    "            \"id\": \"a35d0e80-8c49-415d-b8cb-c21a02627e2b\",\n",
    "            \"submitted\": 1\n",
    "          },\n",
    "          {\n",
    "            \"checked\": false,\n",
    "            \"correct\": true,\n",
    "            \"id\": \"bccd6e2e-2cef-4c72-8bfa-317db0ac48bb\"\n",
    "          },\n",
    "          {\n",
    "            \"checked\": true,\n",
    "            \"at\": \"2018-01-23T14:23:41.791Z\",\n",
    "            \"id\": \"7e0b639a-2ef8-4604-b7eb-5018bd81a91b\",\n",
    "            \"submitted\": 1,\n",
    "            \"correct\": true\n",
    "          }\n",
    "        ],\n",
    "        \"user_submitted\": true,\n",
    "        \"id\": \"bbed4358-999d-4462-9596-bad5173a6ecb\",\n",
    "        \"user_result\": \"incorrect\"\n",
    "      },\n",
    "      {\n",
    "        \"user_incomplete\": false,\n",
    "        \"user_correct\": true,\n",
    "        \"options\": [\n",
    "          {\n",
    "            \"checked\": false,\n",
    "            \"at\": \"2018-01-23T14:23:52.510Z\",\n",
    "            \"id\": \"a9333679-de9d-41ff-bb3d-b239d6b95732\"\n",
    "          },\n",
    "          {\n",
    "            \"checked\": false,\n",
    "            \"id\": \"85795acc-b4b1-4510-bd6e-41648a3553c9\"\n",
    "          },\n",
    "          {\n",
    "            \"checked\": true,\n",
    "            \"at\": \"2018-01-23T14:23:54.223Z\",\n",
    "            \"id\": \"c185ecdb-48fb-4edb-ae4e-0204ac7a0909\",\n",
    "            \"submitted\": 1,\n",
    "            \"correct\": true\n",
    "          },\n",
    "          {\n",
    "            \"checked\": true,\n",
    "            \"at\": \"2018-01-23T14:23:53.862Z\",\n",
    "            \"id\": \"77a66c83-d001-45cd-9a5a-6bba8eb7389e\",\n",
    "            \"submitted\": 1,\n",
    "            \"correct\": true\n",
    "          }\n",
    "        ],\n",
    "        \"user_submitted\": true,\n",
    "        \"id\": \"e6ad8644-96b1-4617-b37b-a263dded202c\",\n",
    "        \"user_result\": \"correct\"\n",
    "      },\n",
    "      {\n",
    "        \"user_incomplete\": false,\n",
    "        \"user_correct\": true,\n",
    "        \"options\": [\n",
    "          {\n",
    "            \"checked\": false,\n",
    "            \"id\": \"59b9fc4b-f239-4850-b1f9-912d1fd3ca13\"\n",
    "          },\n",
    "          {\n",
    "            \"checked\": false,\n",
    "            \"id\": \"2c29e8e8-d4a8-406e-9cdf-de28ec5890fe\"\n",
    "          },\n",
    "          {\n",
    "            \"checked\": false,\n",
    "            \"id\": \"62feee6e-9b76-4123-bd9e-c0b35126b1f1\"\n",
    "          },\n",
    "          {\n",
    "            \"checked\": true,\n",
    "            \"at\": \"2018-01-23T14:24:00.807Z\",\n",
    "            \"id\": \"7f13df9c-fcbe-4424-914f-2206f106765c\",\n",
    "            \"submitted\": 1,\n",
    "            \"correct\": true\n",
    "          }\n",
    "        ],\n",
    "        \"user_submitted\": true,\n",
    "        \"id\": \"95194331-ac43-454e-83de-ea8913067055\",\n",
    "        \"user_result\": \"correct\"\n",
    "      }\n",
    "    ],\n",
    "    \"attempt\": 1,\n",
    "    \"id\": \"5b28a462-7a3b-42e0-b508-09f3906d1703\",\n",
    "    \"counts\": {\n",
    "      \"incomplete\": 1,\n",
    "      \"submitted\": 4,\n",
    "      \"incorrect\": 1,\n",
    "      \"all_correct\": false,\n",
    "      \"correct\": 2,\n",
    "      \"total\": 4,\n",
    "      \"unanswered\": 0\n",
    "    }\n",
    "  },\n",
    "  \"keen_created_at\": \"1516717442.735266\",\n",
    "  \"certification\": \"false\",\n",
    "  \"keen_id\": \"5a6745820eb8ab00016be1f1\",\n",
    "  \"exam_name\": \"Normal Forms and All That Jazz Master Class\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb72f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m78"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
